<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome file</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h2 id="covid-19-reports-source-mapping">COVID-19 Reports Source Mapping</h2>
<p>Covid-19 pandemic has gives us an alternate glimpse of what our daily lives could become in the near future. As the global recession period emerges due to Covid-19, we are advised to quarantine in our homes with our loved ones. Since the world is facing the challenge of understanding this virus, we must stay updated with the news at all times. My question for this project is, “Which news sources are reporting the most updates in regards to the most current Covid-related information?” For this project, I will be using Python and TextBlob, a Python library for processing textual data. The project will first extract data from a Reddit API, specifically the subreddit <a href="r/CovidMapping">r/CovidMapping</a>, a community that solely focuses on updating the users on new confirmed cases or deaths across the world. Then, the project will compare the data complied from CovidMapping to two general subreddits: <a href="r/news">r/news</a> &amp; <a href="r/news">r/NBA</a>, in order to see if there is a difference in the number of reported posts between these reddit communities.</p>
<h2 id="code-walkthrough"><a href="https://github.com/warrenallen/covid202/blob/master/final-report-md-template.md#code-walkthrough"></a>Code Walkthrough</h2>
<p>For the project, I imported some important packages.</p>
<ul>
<li>Package name: json .json exposes the Reddit API from the web page.</li>
<li>Package name: requests .request to send the HTTP requests.</li>
<li>Package name: Unidecode. Unidecode accepts a string values and returns a unicode string.</li>
<li>Package name: TextBlob. TextBlob is a python library for processing textual data.</li>
<li>Package name: NTLK. NTLK is the Natural Language Toolkit, a suite of libraries and programs for symbolic and statistical natural language processing.</li>
<li>Package name: Praw. Praw is a Python Reddit API wrapper that allows simple access to Reddit’s API.</li>
<li>Package name: Pibbledb. Pibble.db allows to save data locally into something close to a database without having to access Reddit API calls again.</li>
</ul>
<p><img src="https://i.ibb.co/BtVqdtw/Code-Image-1-1.png" alt="Import Code"><br>
<em>(Import code with API credentials)</em></p>
<p>The code above is the import code that shows all the packages that the project will be using. I have used the Praw package on line 13, to get my API keys that play a role in the authentication method in order to get access the data from Reddit. In addition, in line 18, I defined my app name as “CovidCaseMaps”.</p>
<p><img src="https://i.ibb.co/Dg8smph/code-image-2.png" alt="First Function"><br>
<em>(First Function)</em><br>
In the code above, line 1, I have called my first function defined as covid_posts with an argument subreddit. The function, from lines 4 to 6, is extracting data from the posts in the Reddit community in .json format as I have passed a user agent to the reddit server in order to obtain data. In addition, lines 8 to 17, the function extracts the “itemdomain” (domain or source of the information on the post), “title” (title of the post) that contains replace statements to replace characters in the string, and “ups” (up-vote number) through the nested objects in the dictionary. This function also involves the extraction and early transformation of the raw data into useful data obtained from the subreddit, CovidMapping.</p>
<p><img src="https://i.ibb.co/rdGhn7C/code-image-3.png" alt="Second Function"><br>
<em>(Second Function)</em></p>
<p>In the code above, line 1 to 2 contains the second function, analyze_cases, and creates an object that is a pointer to an external file through a while expression. The function, analyze_cases, is reading the data collected from the first function (covid_posts), which contains the data from the posts inside of the reddit subreddit. In addition, the function, analyze_cases, extracts any Noun Phrase of the post through the use of patch, TextBlob.</p>
<p><img src="https://i.ibb.co/TbR5dK2/code-image-4.png" alt=""><br>
<em>(First Function call)</em><br>
The code above is the function, covid_posts, is responsible of running it. The codes contain the function name, and its parameter, CovidMapping. In addition, it will open a new csv file called, “COVIDcases.csv”, in which a for loop and an if statement is placed to enable data filtering. For instance, the ups filter from lines 3 to 8, filters the posts from the reddit community to make sure that it has more than 5 up-votes in order to be counted as data for the project.</p>
<p><img src="https://i.ibb.co/7gB2FW7/code-image-5.png" alt=""><br>
<em>(Function call 2)</em><br>
In the code above, in line 1, an object called data is created, and its functions are analyze_cases. The data object contains previously stored data, but in a list posted as { [itemdomain]}, {[ups]}, and {[title]}.   This list can be extracted into “COVIDcases.csv”. “COVIDcases.csv” is the major file that will run and extract out the S String in line 4 containing the Noun Phrase data in the new file “exportdata.csv” through a iterator in line 3. This is the final loading process that will allow to obtain the compiled data that we can use towards the project.</p>
<h2 id="summary-of-results"><a href="https://github.com/warrenallen/covid202/blob/master/final-report-md-template.md#summary-of-results"></a>Summary of Results</h2>
<p>The tool I used after the loading process is Excel. I used excel to visually show which news outlets reported the most cases among three reddit communities through the goal of creating three different bar graphs. I was able to find that the <a href="http://cubadebate.cu">cubadebate.cu</a> from CovidMapping subreddit had the highest and the most frequent amount of posts of 14 reported posts. The second most news outlet was reported in the NBA subreddit by <a href="http://nba.com">nba.com</a> with 8 posts. Lastly, the news subreddit had the least posts as it only had 6 posts by <a href="http://wtoc.com">wtoc.com</a>.</p>
<p><strong>CovidMapping Subreddit</strong><br>
<img src="https://i.ibb.co/RSDLcbV/Covid-Mapping.png" alt=""></p>
<p><strong>News Subreddit</strong><br>
<img src="https://i.ibb.co/nkBvFXt/Newssubreddit.png" alt=""></p>
<p><strong>NBA Subreddit</strong></p>
<p><img src="https://i.ibb.co/wdWdPPF/NBAsubreddit.png" alt=""></p>
<h2 id="what-i-would-do-next"><a href="https://github.com/warrenallen/covid202/blob/master/final-report-md-template.md#what-i-would-do-next"></a>What I Would do Next</h2>
<p>The result from this code helps me to answer that CovidMapping subreddit community has been the most updated with information-related to new Covid-19 cases in comparison to the other two general subreddits, r/NBA and r/News. However, I believe that the r/news subreddit should be on par with r/CovidMapping community in terms of news postings, since it is a large community that advertises itself as a hub for the most-update information on current events. As for the code, the use of Noun Phrase in the second function, analyze_cases, through TextBlob definitely set me back on loading proper data, since the code only extracted some words from the domain and title, which can be tricky when interpreting the data in Excel. Next time, I would definitely prefer to use a word filter rather than a noun phrase filter in order to prevent missing any data on from the post. In addition, I would also put the data filter for the if statement to up-votes of less than five in order to have an increased sampling data in order to evaluate a more concise data  on Excel to better answer my question.</p>
<h2 id="your-full-python-script"><a href="https://github.com/warrenallen/covid202/blob/master/final-report-md-template.md#your-full-python-script"></a>Your full python script</h2>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> requests

<span class="token keyword">import</span> json

<span class="token keyword">from</span> unidecode <span class="token keyword">import</span> unidecode

<span class="token keyword">from</span> textblob <span class="token keyword">import</span> TextBlob

<span class="token keyword">import</span> nltk

<span class="token keyword">import</span> praw

<span class="token keyword">import</span> pickledb

  

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'brown'</span><span class="token punctuation">)</span>

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt'</span><span class="token punctuation">)</span>

reddit <span class="token operator">=</span> praw<span class="token punctuation">.</span>Reddit<span class="token punctuation">(</span>client_id <span class="token operator">=</span> <span class="token string">'ICy11BzMfMvZDQ'</span><span class="token punctuation">,</span>

client_secret <span class="token operator">=</span> <span class="token string">'1YNi5EzkghO5MIrTkuMjYhtUaXk'</span><span class="token punctuation">,</span>

user_agent <span class="token operator">=</span> <span class="token string">'Covid Case Maps'</span><span class="token punctuation">)</span>

  
  

my_app_name <span class="token operator">=</span> <span class="token string">"CovidCaseMaps"</span>

  
  

<span class="token keyword">def</span> <span class="token function">covid_posts</span><span class="token punctuation">(</span>subreddit<span class="token punctuation">)</span><span class="token punctuation">:</span>

  
  

url <span class="token operator">=</span> f<span class="token string">'https://www.reddit.com/r/{subreddit}.json'</span>

head <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user-agent'</span><span class="token punctuation">:</span> my_app_name<span class="token punctuation">}</span> <span class="token comment">#creating a dictionary with key</span>

redditdata <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span>head<span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>

  

listings <span class="token operator">=</span> redditdata<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'children'</span><span class="token punctuation">]</span>

returndata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

  
  

<span class="token keyword">for</span> item <span class="token keyword">in</span> listings<span class="token punctuation">:</span>

thisitem <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

thisitem<span class="token punctuation">[</span><span class="token string">'itemdomain'</span><span class="token punctuation">]</span> <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'domain'</span><span class="token punctuation">]</span>

thisitem<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> unidecode<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span>

thisitem<span class="token punctuation">[</span><span class="token string">'ups'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">int</span> <span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'ups'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

returndata<span class="token punctuation">.</span>append<span class="token punctuation">(</span>thisitem<span class="token punctuation">)</span>

<span class="token keyword">return</span><span class="token punctuation">(</span>returndata<span class="token punctuation">)</span>

  
  

<span class="token keyword">def</span> <span class="token function">analyze_cases</span><span class="token punctuation">(</span>sourcefile<span class="token punctuation">,</span> floor<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

<span class="token keyword">with</span>  <span class="token builtin">open</span><span class="token punctuation">(</span>sourcefile<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span>  <span class="token builtin">file</span><span class="token punctuation">:</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Reading file...\n"</span><span class="token punctuation">)</span>

<span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>

blob <span class="token operator">=</span> TextBlob<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

output <span class="token operator">=</span> blob<span class="token punctuation">.</span>noun_phrases

returndata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> term <span class="token keyword">in</span>  <span class="token builtin">set</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">:</span>

termcount <span class="token operator">=</span> output<span class="token punctuation">.</span>count<span class="token punctuation">(</span>term<span class="token punctuation">)</span>

<span class="token keyword">if</span> termcount <span class="token operator">&gt;</span> floor<span class="token punctuation">:</span>

returndata<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>term<span class="token punctuation">,</span> termcount<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">else</span><span class="token punctuation">:</span>

<span class="token keyword">pass</span>

<span class="token keyword">return</span> returndata

  
  

returndata <span class="token operator">=</span> covid_posts<span class="token punctuation">(</span><span class="token string">"CovidMapping"</span><span class="token punctuation">)</span>

<span class="token keyword">with</span>  <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'COVIDcases.csv'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> myfile<span class="token punctuation">:</span>

<span class="token keyword">for</span> post <span class="token keyword">in</span> returndata<span class="token punctuation">:</span>

<span class="token keyword">if</span> post <span class="token punctuation">[</span><span class="token string">'ups'</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">5</span><span class="token punctuation">:</span>

line <span class="token operator">=</span> <span class="token punctuation">(</span>f<span class="token string">"{post['itemdomain']},{post['ups']},{post['title']}\n"</span><span class="token punctuation">)</span>

myfile<span class="token punctuation">.</span>write<span class="token punctuation">(</span>line<span class="token punctuation">)</span>

<span class="token keyword">else</span><span class="token punctuation">:</span>

<span class="token keyword">pass</span>

  

data <span class="token operator">=</span> analyze_cases<span class="token punctuation">(</span><span class="token string">'COVIDcases.csv'</span><span class="token punctuation">)</span>

<span class="token keyword">with</span>  <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'exportdata.csv'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> output<span class="token punctuation">:</span>

<span class="token keyword">for</span> pair <span class="token keyword">in</span> data<span class="token punctuation">:</span>

output<span class="token punctuation">.</span>write<span class="token punctuation">(</span>f<span class="token string">'{pair[0]},{pair[1]}\n'</span><span class="token punctuation">)</span>
</code></pre>
</div>
</body>

</html>
